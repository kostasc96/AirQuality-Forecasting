{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, GRU, SimpleRNN, Dense, GlobalMaxPool1D,Reshape,Dropout,Lambda\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import layers,models,Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "#import tensorflow.initializers as initializers \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = 'CleanFiles/'\n",
    "files_format = '.csv'\n",
    "files_postfix = 'Extract'\n",
    "# file_names = ['AgiaParaskevi','Aristotelous','Elefsina',\n",
    "#               'Lykovrisi','Marousi','NeaSmirni','Peristeri',\n",
    "#               'Pireus','Thrakomakedones']\n",
    "file_names = [\n",
    "              'Marousi',\n",
    "              'Aristotelous',\n",
    "              'NeaSmirni',\n",
    "              'AgiaParaskevi',\n",
    "              'Pireus',\n",
    "              'Peristeri'\n",
    "             ]\n",
    "\n",
    "# file_names = [\n",
    "#               'Marousi'\n",
    "#              ]\n",
    "\n",
    "file_names_nogrid = [\n",
    "                'Thrakomakedones',\n",
    "                'Elefsina'\n",
    "            ]\n",
    "\n",
    "grid = {'Marousi': ['Lykovrisi','Peristeri','AgiaParaskevi']\n",
    "        ,'Aristotelous': ['Marousi','Peristeri','NeaSmirni']\n",
    "        ,'AgiaParaskevi': ['Marousi','NeaSmirni','Koropi']\n",
    "        ,'NeaSmirni': ['Aristotelous','Pireus','AgiaParaskevi']\n",
    "        ,'Pireus': ['Elefsina','Peristeri','NeaSmirni']\n",
    "        ,'Peristeri':['Thrakomakedones','Marousi','Pireus']\n",
    "       }\n",
    "\n",
    "\n",
    "grid2 = {'Marousi': ['Lykovrisi','Aristotelous']\n",
    "        ,'Aristotelous': ['Marousi','Peristeri']\n",
    "        ,'AgiaParaskevi': ['Marousi','Koropi']\n",
    "        ,'NeaSmirni': ['Aristotelous','Pireus']\n",
    "        ,'Pireus': ['Elefsina','NeaSmirni']\n",
    "        ,'Peristeri':['Thrakomakedones','Marousi']\n",
    "       }\n",
    "\n",
    "\n",
    "file_names_mock = [\n",
    "                'Elefsina'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pm10_index(val):\n",
    "    if val <= 25.0:\n",
    "        return 0\n",
    "    elif 26.0 <= val <= 50.0:\n",
    "        return 1\n",
    "    elif 51.0 <= val <= 90.0:\n",
    "        return 2\n",
    "    elif 91.0 <= val <= 180.0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(tmp):\n",
    "    return tmp[11:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(tmp):\n",
    "    if tmp == 'Spring':\n",
    "        return '1'\n",
    "    elif tmp == 'Spring/Summer':\n",
    "        return '2'\n",
    "    elif tmp == 'Summer':\n",
    "        return '3'\n",
    "    elif tmp == 'Summer/Autumn':\n",
    "        return '4'\n",
    "    elif tmp == 'Autumn':\n",
    "        return '5'\n",
    "    elif tmp == 'Autumn/Winter':\n",
    "        return '6'\n",
    "    elif tmp == 'Winter/Spring':\n",
    "        return '7'\n",
    "    else:\n",
    "        return '8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winddir(tmp):\n",
    "    if tmp == 'N':\n",
    "        return '1'\n",
    "    elif tmp == 'NNE':\n",
    "        return '2'\n",
    "    elif tmp == 'NE':\n",
    "        return '3'\n",
    "    elif tmp == 'ENE':\n",
    "        return '4'\n",
    "    elif tmp == 'E':\n",
    "        return '5'\n",
    "    elif tmp == 'ESE':\n",
    "        return '6'\n",
    "    elif tmp == 'SE':\n",
    "        return '7'\n",
    "    elif tmp == 'SSE':\n",
    "        return '8'\n",
    "    elif tmp == 'S':\n",
    "        return '9'\n",
    "    elif tmp == 'SSW':\n",
    "        return '10'\n",
    "    elif tmp == 'SW':\n",
    "        return '11'\n",
    "    elif tmp == 'WSW':\n",
    "        return '12'\n",
    "    elif tmp == 'W':\n",
    "        return '13'\n",
    "    elif tmp == 'WNW':\n",
    "        return '14'\n",
    "    elif tmp == 'NW':\n",
    "        return '15'\n",
    "    else:\n",
    "        return '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neasmirni = pd.read_csv('CleanFiles/NeaSmirniExtract.csv', sep=',')\n",
    "#neasmirni = neasmirni[['date_time','station_id','season','real_temp','real_windspd','real_winddir','real_humidity','forecast_tempC','forecast_windSpeed','forecast_windDirection','forecast_humidity','pm10']]\n",
    "#neasmirni['pm10'] = neasmirni['pm10'].map(lambda a: pm10_index(a))\n",
    "#temp = pd.read_csv('CleanFiles/PeristeriExtract.csv', sep=',')\n",
    "#agiaparaskevi = pd.read_csv('CleanFiles/AgiaParaskeviExtract.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = 72\n",
    "# D = 1\n",
    "# X = []\n",
    "# Y = []\n",
    "# for t in range(len(neasmirni) - T):\n",
    "#     x = neasmirni[t:t+T]\n",
    "#     X.append(x)\n",
    "#     y = neasmirni[t:t+T]\n",
    "#     Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pm10_index(predicts, test):\n",
    "    for i in range(len(predicts)):\n",
    "        for j in range(len(predicts[i])):\n",
    "            predicts[i][j] = pm10_index(predicts[i][j])\n",
    "            test[i][j] = pm10_index(test[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pm10_accuracy(predicts, test, window):\n",
    "    tot_val = len(predicts) * window \n",
    "    tot_comp = 0\n",
    "    for i in range(len(predicts)):\n",
    "        for j in range(window):\n",
    "            if(abs(predicts[i][j] - test[i][j]) == 1):\n",
    "                tot_comp =  tot_comp + 0.5\n",
    "            elif(abs(predicts[i][j] == test[i][j])):\n",
    "                tot_comp =  tot_comp + 1\n",
    "    return (100*tot_comp)/tot_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xy(series, series2, window_size, prediction_horizon, shuffle = False):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(0, len(series)):\n",
    "        if len(series[(i + window_size):(i + window_size + prediction_horizon)]) < prediction_horizon:\n",
    "            break\n",
    "        x.append(np.array(series[i:(i + window_size)]))\n",
    "        y.append(np.array(series2[(i + window_size):(i + window_size + prediction_horizon)]))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': 2000,\n",
    "    'max_depth': 4,\n",
    "    'num_leaves': 2**4,\n",
    "    'learning_rate': 0.1,\n",
    "    'boosting_type': 'dart'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(actual, predicted):\n",
    "    if not all([isinstance(actual, np.ndarray), \n",
    "                isinstance(predicted, np.ndarray)]):\n",
    "        actual, predicted = np.array(actual),\n",
    "        np.array(predicted)\n",
    "  \n",
    "    return round(\n",
    "        np.mean(\n",
    "            np.abs(predicted - actual) / \n",
    "            ((np.abs(predicted) + np.abs(actual))/2)\n",
    "        )*100, 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units,drop,features, window, horizon):\n",
    "    encoder_inputs = layers.Input(shape=(window,features))\n",
    "    encoder = GRU(units, dropout=drop,return_state=True)\n",
    "    _,encoder_states = encoder(encoder_inputs)\n",
    "    decoder=layers.RepeatVector(horizon)(encoder_states)\n",
    "    out = layers.TimeDistributed(Dense(1))(decoder)\n",
    "    model = models.Model(encoder_inputs, out)\n",
    "    model.compile(loss='mse', optimizer=RMSprop())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq(window, horizon, units,bn,drop,feautures,channel=1):\n",
    "    encoder_inputs = layers.Input(shape=(window,feautures))\n",
    "\n",
    "    encoder = GRU(units, dropout=drop,return_state=True)\n",
    "    _,encoder_states = encoder(encoder_inputs)\n",
    "    if bn:\n",
    "        encoder_states=layers.BatchNormalization()(encoder_states)\n",
    "    decoder=layers.RepeatVector(horizon)(encoder_states)\n",
    "    decoder_gru = GRU(units, dropout=drop, return_sequences=True, return_state=False)\n",
    "    decoder = decoder_gru(decoder, initial_state=encoder_states)\n",
    "    \n",
    "    out = layers.TimeDistributed(Dense(channel,use_bias=True))(decoder)\n",
    "    model = models.Model(encoder_inputs, out)\n",
    "    model.compile(loss='mse', optimizer=RMSprop(),metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatedDNN(units,features, horizon):\n",
    "#     model = Sequential()\n",
    "#     model.add(layers.Input(shape=(72,features)))\n",
    "#     model.add(layers.Dense(2, activation='relu'))\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "    model = Sequential([\n",
    "    Lambda(lambda x: x[:, -1:, :]),\n",
    "    Dense(units, activation='relu',use_bias=True),\n",
    "    Dense(horizon*1),\n",
    "    Reshape([horizon, 1])\n",
    "    ])\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.compile(loss='mse', optimizer=RMSprop(),metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(features, window, horizon):\n",
    "    model = Sequential([\n",
    "    LSTM(10, input_shape=(window, features), return_sequences=True),\n",
    "    Dropout(0.5),\n",
    "    LSTM(10, return_sequences=True),\n",
    "    Dense(horizon),\n",
    "    Reshape([horizon, 1])\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=RMSprop(), loss='mse', metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm():\n",
    "    model = lgb.LGBMRegressor(first_metric_only = True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadToModel(files, formating, pathFiles, postfx, params):\n",
    "    T = 72\n",
    "    D = 1\n",
    "    X = []\n",
    "    Y = []\n",
    "    for fileName in files:\n",
    "        window = 72 \n",
    "        horizon = 48\n",
    "        accuracy = 0\n",
    "        #df = pd.read_csv(pathFiles + fileName + postfx + formating, sep=',')\n",
    "        df = pd.read_csv(pathFiles + fileName + formating, sep=',')\n",
    "        df['date_time'] = df['date_time'].astype(\"|S\")\n",
    "        df['season'] = df['season'].astype(\"|S\")\n",
    "        df['date_time'] = df['date_time'].map(lambda a: get_time(a))\n",
    "        df['date_time'] = df['date_time'].astype(int)\n",
    "        df['season'] = df['season'].map(lambda a: get_season(a))\n",
    "        df['season'] = df['season'].astype(np.float64)\n",
    "        df['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        df['station_id'] = df['station_id'].astype(int)\n",
    "        df2 = df[['pm10']]\n",
    "        \n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(-3, 3))\n",
    "        names = ['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10']\n",
    "        df[['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10']] = scaler.fit_transform(df[['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10']])\n",
    "        \n",
    "        \n",
    "        scaler1 = MinMaxScaler(feature_range=(-3, 3))\n",
    "        df2 = scaler1.fit_transform(df2.values)\n",
    "        \n",
    "\n",
    "        X,y = create_xy(df[['station_id','date_time','forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10']],df2,window, horizon)\n",
    "        accuracy = 0.0\n",
    "        \n",
    "        print(fileName + ' begins prediction')\n",
    "#         model = seq2seq(72,48,50,True,0.5,7,1)\n",
    "#         model = gru(5,0.5,7, 72, 48)\n",
    "#         model = lstm(5, window, horizon)\n",
    "#         model = lightgbm()\n",
    "        model = gatedDNN(100,7, horizon)\n",
    "\n",
    "        kf = KFold(n_splits=5)\n",
    "\n",
    "#         print(X.shape)\n",
    "#         print(y.shape)\n",
    "        \n",
    "        epochs = 2\n",
    "        batch_size = 32\n",
    "\n",
    "        predicts = []\n",
    "        tests = []\n",
    "#         for trainI,testI in kf.split(X):\n",
    "#             model.fit(X[trainI],y[trainI], epochs=epochs, batch_size=batch_size)\n",
    "#             predictions = model.predict(X[testI])\n",
    "#             predictions = scaler.inverse_transform(predictions.reshape(-1,1)).reshape(predictions.shape)\n",
    "#             predicts.append(predictions)\n",
    "#             tests.append(y[testI])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "        model.fit(X_train,y_train, epochs=epochs, batch_size=batch_size)\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions = scaler1.inverse_transform(predictions.reshape(-1,1)).reshape(predictions.shape)\n",
    "        y_test = scaler1.inverse_transform(y_test.reshape(-1,1)).reshape(y_test.shape)\n",
    "\n",
    "    return predictions, y_test, model, scaler, scaler1, tmpDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadToModelGrid2(files, formating, pathFiles, postfx, params):\n",
    "    T = 72\n",
    "    D = 1\n",
    "    X = []\n",
    "    Y = []\n",
    "    for fileName in files:\n",
    "        window = 72 \n",
    "        horizon = 48\n",
    "        accuracy = 0\n",
    "        characteristics = 10\n",
    "        df = pd.read_csv(pathFiles + fileName + formating, sep=',')\n",
    "        df1 = pd.read_csv(pathFiles + grid2[fileName][0] + formating, sep=',')\n",
    "        df2 = pd.read_csv(pathFiles + grid2[fileName][1] + formating, sep=',')\n",
    "        df['date_time'] = df['date_time'].astype(\"|S\")\n",
    "        df['season'] = df['season'].astype(\"|S\")\n",
    "        df['date_time'] = df['date_time'].map(lambda a: get_time(a))\n",
    "        df['date_time'] = df['date_time'].astype(int)\n",
    "        df['season'] = df['season'].map(lambda a: get_season(a))\n",
    "        df['season'] = df['season'].astype(np.float64)\n",
    "        df['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        df1['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        df2['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        df['station_id'] = df['station_id'].astype(int)\n",
    "        df['windir1'] = df1['forecast_windDirection']\n",
    "        df['pm101'] = df1['pm10']\n",
    "        df['windir2'] = df2['forecast_windDirection']\n",
    "        df['pm102'] = df2['pm10']\n",
    "        \n",
    "        df2 = df[['pm10']]\n",
    "        \n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(-3, 3))\n",
    "        names = ['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10','windir1','pm101','windir2','pm102']\n",
    "        df[['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10','windir1','pm101','windir2','pm102']] = scaler.fit_transform(df[['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10','windir1','pm101','windir2','pm102']])\n",
    "        \n",
    "        \n",
    "        scaler1 = MinMaxScaler(feature_range=(-3, 3))\n",
    "        df2 = scaler1.fit_transform(df2.values)\n",
    "        \n",
    "\n",
    "        X,y = create_xy(df[['station_id','date_time','forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10','windir1','pm101','windir2','pm102']],df2,window, horizon)\n",
    "        accuracy = 0.0\n",
    "        \n",
    "        print(fileName + ' begins prediction')\n",
    "#         model = seq2seq(72,48,50,True,0.5,15,1)\n",
    "#         model = gru(5,0.5,15, 72, 48)\n",
    "#         model = lstm(15, window, horizon)\n",
    "#         model = lightgbm()\n",
    "        model = gatedDNN(100,characteristics, horizon)\n",
    "\n",
    "        kf = KFold(n_splits=5)\n",
    "\n",
    "#         print(X.shape)\n",
    "#         print(y.shape)\n",
    "        \n",
    "        epochs = 2\n",
    "        batch_size = 32\n",
    "\n",
    "        predicts = []\n",
    "        tests = []\n",
    "#         for trainI,testI in kf.split(X):\n",
    "#             model.fit(X[trainI],y[trainI], epochs=epochs, batch_size=batch_size)\n",
    "#             predictions = model.predict(X[testI])\n",
    "#             predictions = scaler.inverse_transform(predictions.reshape(-1,1)).reshape(predictions.shape)\n",
    "#             predicts.append(predictions)\n",
    "#             tests.append(y[testI])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "        model.fit(X_train,y_train, epochs=epochs, batch_size=batch_size)\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions = scaler1.inverse_transform(predictions.reshape(-1,1)).reshape(predictions.shape)\n",
    "        y_test = scaler1.inverse_transform(y_test.reshape(-1,1)).reshape(y_test.shape)\n",
    "\n",
    "    return predictions, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadToModelGrid3(files, formating, pathFiles, postfx, params):\n",
    "    T = 72\n",
    "    D = 1\n",
    "    X = []\n",
    "    Y = []\n",
    "    for fileName in files:\n",
    "        window = 72 \n",
    "        horizon = 48\n",
    "        accuracy = 0\n",
    "        characteristics = 12\n",
    "        #df = pd.read_csv(pathFiles + fileName + postfx + formating, sep=',')\n",
    "        df = pd.read_csv(pathFiles + fileName + formating, sep=',')\n",
    "        df1 = pd.read_csv(pathFiles + grid[fileName][0] + formating, sep=',')\n",
    "        df2 = pd.read_csv(pathFiles + grid[fileName][1] + formating, sep=',')\n",
    "        df3 = pd.read_csv(pathFiles + grid[fileName][2] + formating, sep=',')\n",
    "#         df4 = pd.read_csv(pathFiles + grid[fileName][3] + formating, sep=',')\n",
    "        df['date_time'] = df['date_time'].astype(\"|S\")\n",
    "        df['season'] = df['season'].astype(\"|S\")\n",
    "        df['date_time'] = df['date_time'].map(lambda a: get_time(a))\n",
    "        df['date_time'] = df['date_time'].astype(int)\n",
    "        df['season'] = df['season'].map(lambda a: get_season(a))\n",
    "        df['season'] = df['season'].astype(np.float64)\n",
    "        df['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        df1['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        df2['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        df3['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        df['station_id'] = df['station_id'].astype(int)\n",
    "        df['windir1'] = df1['forecast_windDirection']\n",
    "        df['pm101'] = df1['pm10']\n",
    "        df['windir2'] = df2['forecast_windDirection']\n",
    "        df['pm102'] = df2['pm10']\n",
    "        df['windir3'] = df3['forecast_windDirection']\n",
    "        df['pm103'] = df3['pm10']\n",
    "        \n",
    "        df2 = df[['pm10']]\n",
    "        \n",
    "\n",
    "        scaler = MinMaxScaler(feature_range=(-3, 3))\n",
    "        names = ['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10','windir1','pm101','windir2','pm102','windir3','pm103']\n",
    "        df[['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10','windir1','pm101','windir2','pm102','windir3','pm103']] = scaler.fit_transform(df[['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10','windir1','pm101','windir2','pm102','windir3','pm103']])\n",
    "        \n",
    "        \n",
    "        scaler1 = MinMaxScaler(feature_range=(-3, 3))\n",
    "        df2 = scaler1.fit_transform(df2.values)\n",
    "        \n",
    "\n",
    "        X,y = create_xy(df[['station_id','date_time','forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10','windir1','pm101','windir2','pm102','windir3','pm103']],df2,window, horizon)\n",
    "        accuracy = 0.0\n",
    "        \n",
    "        print(fileName + ' begins prediction')\n",
    "#         model = seq2seq(72,48,50,True,0.5,15,1)\n",
    "#         model = gru(5,0.5,15, 72, 48)\n",
    "#         model = lstm(15, window, horizon)\n",
    "#         model = lightgbm()\n",
    "        model = gatedDNN(300,characteristics, horizon)\n",
    "\n",
    "        kf = KFold(n_splits=5)\n",
    "\n",
    "#         print(X.shape)\n",
    "#         print(y.shape)\n",
    "        \n",
    "        epochs = 2\n",
    "        batch_size = 32\n",
    "\n",
    "        predicts = []\n",
    "        tests = []\n",
    "#         for trainI,testI in kf.split(X):\n",
    "#             model.fit(X[trainI],y[trainI], epochs=epochs, batch_size=batch_size)\n",
    "#             predictions = model.predict(X[testI])\n",
    "#             predictions = scaler.inverse_transform(predictions.reshape(-1,1)).reshape(predictions.shape)\n",
    "#             predicts.append(predictions)\n",
    "#             tests.append(y[testI])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "        model.fit(X_train,y_train, epochs=epochs, batch_size=batch_size)\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions = scaler1.inverse_transform(predictions.reshape(-1,1)).reshape(predictions.shape)\n",
    "        y_test = scaler1.inverse_transform(y_test.reshape(-1,1)).reshape(y_test.shape)\n",
    "\n",
    "    return predictions, y_test, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mockPredictions(files, formating, pathFiles, postfx, params):\n",
    "    T = 72\n",
    "    D = 1\n",
    "    X = []\n",
    "    Y = []\n",
    "    for fileName in file_names_mock:\n",
    "        window = 72 \n",
    "        horizon = 48\n",
    "        accuracy = 0\n",
    "        characteristics = 12\n",
    "        df = pd.read_csv(pathFiles + fileName + formating, sep=',')\n",
    "        df['date_time'] = df['date_time'].astype(\"|S\")\n",
    "        df['season'] = df['season'].astype(\"|S\")\n",
    "        df['date_time'] = df['date_time'].map(lambda a: get_time(a))\n",
    "        df['date_time'] = df['date_time'].astype(int)\n",
    "        df['season'] = df['season'].map(lambda a: get_season(a))\n",
    "        df['season'] = df['season'].astype(np.float64)\n",
    "        df['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        df['station_id'] = df['station_id'].astype(int)\n",
    "        \n",
    "        df2 = df[['pm10']]\n",
    "        \n",
    "        scaler = MinMaxScaler(feature_range=(-3, 3))\n",
    "        names = ['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10']\n",
    "        df[['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10']] = scaler.fit_transform(df[['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10']])\n",
    "        \n",
    "        \n",
    "        scaler1 = MinMaxScaler(feature_range=(-3, 3))\n",
    "        df2 = scaler1.fit_transform(df2.values)\n",
    "        \n",
    "\n",
    "        X,y = create_xy(df[['station_id','date_time','forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10']],df2,window, horizon)\n",
    "        accuracy = 0.0\n",
    "        \n",
    "\n",
    "        return X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marousi begins prediction\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020530AD8378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020530AD8378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "916/916 [==============================] - 2s 2ms/step - loss: 0.9992 - mean_squared_error: 0.9992\n",
      "Epoch 2/2\n",
      "916/916 [==============================] - 3s 3ms/step - loss: 0.0335 - mean_squared_error: 0.0335\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000020530166378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000020530166378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Aristotelous begins prediction\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002052FF9D8C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002052FF9D8C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "916/916 [==============================] - 2s 1ms/step - loss: 0.9929 - mean_squared_error: 0.9929\n",
      "Epoch 2/2\n",
      "916/916 [==============================] - 2s 2ms/step - loss: 0.0373 - mean_squared_error: 0.0373\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002057D03D510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002057D03D510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "NeaSmirni begins prediction\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020530A59C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020530A59C80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "916/916 [==============================] - 3s 3ms/step - loss: 1.1543 - mean_squared_error: 1.1543\n",
      "Epoch 2/2\n",
      "916/916 [==============================] - 1s 1ms/step - loss: 0.0326 - mean_squared_error: 0.0326\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002057D03DEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002057D03DEA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "AgiaParaskevi begins prediction\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002053061C048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002053061C048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "916/916 [==============================] - 3s 3ms/step - loss: 1.1975 - mean_squared_error: 1.1974\n",
      "Epoch 2/2\n",
      "916/916 [==============================] - 3s 3ms/step - loss: 0.0241 - mean_squared_error: 0.0241\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002057D14D950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000002057D14D950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pireus begins prediction\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002057D0F97B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002057D0F97B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "916/916 [==============================] - 2s 1ms/step - loss: 1.0127 - mean_squared_error: 1.0127\n",
      "Epoch 2/2\n",
      "916/916 [==============================] - 2s 3ms/step - loss: 0.0630 - mean_squared_error: 0.0630\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000020531CEE0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000020531CEE0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Peristeri begins prediction\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020575F56268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000020575F56268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "916/916 [==============================] - 3s 3ms/step - loss: 0.9790 - mean_squared_error: 0.9790\n",
      "Epoch 2/2\n",
      "916/916 [==============================] - 2s 3ms/step - loss: 0.0378 - mean_squared_error: 0.0378\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000205303B32F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000205303B32F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "predicts, test, model1 = loadToModelGrid3(file_names, files_format, files_path, files_postfix, parameters)\n",
    "#predicts, test = loadToModel(file_names, files_format, files_path, files_postfix, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#predicts[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.8455806\n",
      "0.0\n",
      "232.04393\n",
      "802.0\n"
     ]
    }
   ],
   "source": [
    "print(np.amin(predicts))\n",
    "print(np.amin(test))\n",
    "print(np.amax(predicts))\n",
    "print(np.amax(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_pm10_index(predicts, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.56005012357656\n"
     ]
    }
   ],
   "source": [
    "print(calc_pm10_accuracy(predicts,test,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('models/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thrakomakedones begins prediction\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002052FF9D730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002052FF9D730> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "916/916 [==============================] - 2s 1ms/step - loss: 2.2446 - mean_squared_error: 2.2446\n",
      "Epoch 2/2\n",
      "916/916 [==============================] - 2s 3ms/step - loss: 0.0316 - mean_squared_error: 0.0316\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000020530166488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000020530166488> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Elefsina begins prediction\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002052FFDDF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002052FFDDF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "916/916 [==============================] - 2s 1ms/step - loss: 1.8920 - mean_squared_error: 1.8920\n",
      "Epoch 2/2\n",
      "916/916 [==============================] - 2s 2ms/step - loss: 0.0256 - mean_squared_error: 0.0256\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000020575FDA158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000020575FDA158> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "predicts, test, model2, sc1, sc2, tmpDf = loadToModel(file_names_nogrid, files_format, files_path, files_postfix, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicts[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5303736\n",
      "0.0\n",
      "157.753\n",
      "684.0\n"
     ]
    }
   ],
   "source": [
    "print(np.amin(predicts))\n",
    "print(np.amin(test))\n",
    "print(np.amax(predicts))\n",
    "print(np.amax(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_pm10_index(predicts, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.66660892061073\n"
     ]
    }
   ],
   "source": [
    "print(calc_pm10_accuracy(predicts,test,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('models/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model1 = load_model('models/model1.h5')\n",
    "new_model2 = load_model('models/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDs = mockPredictions(file_names_nogrid, files_format, files_path, files_postfix, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 7)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpDs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmpDsX, tmpDsY = create_xy(tmpDs[['forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection','pm10']], tmpDs[['pm10']], 72, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 72, 7) for input KerasTensor(type_spec=TensorSpec(shape=(None, 72, 7), dtype=tf.float32, name='lambda_14_input'), name='lambda_14_input', description=\"created by layer 'lambda_14_input'\"), but it was called on an input with incompatible shape (None, None).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"lambda_14\" (type Lambda).\n\nIndex out of range using input dim 2; input has only 2 dims for '{{node sequential_14/lambda_14/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=5, ellipsis_mask=0, end_mask=7, new_axis_mask=0, shrink_axis_mask=0](IteratorGetNext, sequential_14/lambda_14/strided_slice/stack, sequential_14/lambda_14/strided_slice/stack_1, sequential_14/lambda_14/strided_slice/stack_2)' with input shapes: [?,?], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, None), dtype=float32)\n  • mask=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-1fbd62ce664f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmpDs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\keras\\layers\\core\\lambda_layer.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     model = Sequential([\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhorizon\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"lambda_14\" (type Lambda).\n\nIndex out of range using input dim 2; input has only 2 dims for '{{node sequential_14/lambda_14/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=5, ellipsis_mask=0, end_mask=7, new_axis_mask=0, shrink_axis_mask=0](IteratorGetNext, sequential_14/lambda_14/strided_slice/stack, sequential_14/lambda_14/strided_slice/stack_1, sequential_14/lambda_14/strided_slice/stack_2)' with input shapes: [?,?], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, None), dtype=float32)\n  • mask=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "new_model2.predict(tmpDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_axes(df):\n",
    "    x = np.arange(df.shape[0])[:, None, None]\n",
    "    y = np.arange(df.shape[1])[None, :, None]\n",
    "    z = np.arange(df.shape[2])[None, None, :]\n",
    "    x, y, z = np.broadcast_arrays(x, y, z)\n",
    "    return x,y,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, z = return_axes(predicts)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.gca(projection='3d')\n",
    "# ax.scatter(x.ravel(),\n",
    "#            y.ravel(),\n",
    "#            z.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, z = return_axes(test)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.gca(projection='3d')\n",
    "# ax.scatter(x.ravel(),\n",
    "#            y.ravel(),\n",
    "#            z.ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
