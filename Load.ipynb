{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, GRU, SimpleRNN, Dense, GlobalMaxPool1D,Reshape,Dropout,Lambda\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import layers,models,Sequential\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = 'CleanFiles/'\n",
    "files_format = '.csv'\n",
    "files_postfix = 'Extract'\n",
    "# file_names = ['AgiaParaskevi','Aristotelous','Athens','Elefsina','Koropi','Liosia',\n",
    "#               'Lykovrisi','Marousi','NeaSmirni','Patision','Peristeri',\n",
    "#               'Pireus','Thrakomakedones']\n",
    "file_names = ['AgiaParaskevi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pm10_index(val):\n",
    "    if val <= 25.0:\n",
    "        return 0\n",
    "    elif 26.0 <= val <= 50.0:\n",
    "        return 1\n",
    "    elif 51.0 <= val <= 90.0:\n",
    "        return 2\n",
    "    elif 91.0 <= val <= 180.0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(tmp):\n",
    "    return tmp[11:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(tmp):\n",
    "    if tmp == 'Spring':\n",
    "        return '1'\n",
    "    elif tmp == 'Spring/Summer':\n",
    "        return '2'\n",
    "    elif tmp == 'Summer':\n",
    "        return '3'\n",
    "    elif tmp == 'Summer/Autumn':\n",
    "        return '4'\n",
    "    elif tmp == 'Autumn':\n",
    "        return '5'\n",
    "    elif tmp == 'Autumn/Winter':\n",
    "        return '6'\n",
    "    elif tmp == 'Winter/Spring':\n",
    "        return '7'\n",
    "    else:\n",
    "        return '8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winddir(tmp):\n",
    "    if tmp == 'N':\n",
    "        return '1'\n",
    "    elif tmp == 'NNE':\n",
    "        return '2'\n",
    "    elif tmp == 'NE':\n",
    "        return '3'\n",
    "    elif tmp == 'ENE':\n",
    "        return '4'\n",
    "    elif tmp == 'E':\n",
    "        return '5'\n",
    "    elif tmp == 'ESE':\n",
    "        return '6'\n",
    "    elif tmp == 'SE':\n",
    "        return '7'\n",
    "    elif tmp == 'SSE':\n",
    "        return '8'\n",
    "    elif tmp == 'S':\n",
    "        return '9'\n",
    "    elif tmp == 'SSW':\n",
    "        return '10'\n",
    "    elif tmp == 'SW':\n",
    "        return '11'\n",
    "    elif tmp == 'WSW':\n",
    "        return '12'\n",
    "    elif tmp == 'W':\n",
    "        return '13'\n",
    "    elif tmp == 'WNW':\n",
    "        return '14'\n",
    "    elif tmp == 'NW':\n",
    "        return '15'\n",
    "    else:\n",
    "        return '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neasmirni = pd.read_csv('CleanFiles/NeaSmirniExtract.csv', sep=',')\n",
    "#neasmirni = neasmirni[['date_time','station_id','season','real_temp','real_windspd','real_winddir','real_humidity','forecast_tempC','forecast_windSpeed','forecast_windDirection','forecast_humidity','pm10']]\n",
    "#neasmirni['pm10'] = neasmirni['pm10'].map(lambda a: pm10_index(a))\n",
    "#temp = pd.read_csv('CleanFiles/PeristeriExtract.csv', sep=',')\n",
    "#agiaparaskevi = pd.read_csv('CleanFiles/AgiaParaskeviExtract.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = 72\n",
    "# D = 1\n",
    "# X = []\n",
    "# Y = []\n",
    "# for t in range(len(neasmirni) - T):\n",
    "#     x = neasmirni[t:t+T]\n",
    "#     X.append(x)\n",
    "#     y = neasmirni[t:t+T]\n",
    "#     Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xy(series, series2, window_size, prediction_horizon, shuffle = False):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(0, len(series)):\n",
    "        if len(series[(i + window_size):(i + window_size + prediction_horizon)]) < prediction_horizon:\n",
    "            break\n",
    "        x.append(np.array(series[i:(i + window_size)]))\n",
    "        y.append(np.array(series2[(i + window_size):(i + window_size + prediction_horizon)]))\n",
    "#         x.append(np.array(series[i:i+window_size][['station_id','season','real_temp','real_humidity','real_windspd','real_winddir','forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection']]))\n",
    "#         y.append(np.array(series[i+window_size:i+window_size+prediction_horizon]['pm10']))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': 2000,\n",
    "    'max_depth': 4,\n",
    "    'num_leaves': 2**4,\n",
    "    'learning_rate': 0.1,\n",
    "    'boosting_type': 'dart'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units,drop,out_features):\n",
    "\n",
    "    input=layers.Input(shape=(72,10))\n",
    "    result=GRU(units,dropout=drop,return_sequences=False)(input)\n",
    "    result=layers.Dense(2)(result)\n",
    "    result=Reshape(target_shape=(48,out_features))(result)\n",
    "    \n",
    "    return Model(inputs=input,outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq(units,bn,drop,feautures,channel=1):\n",
    "    encoder_inputs = layers.Input(shape=(72,feautures))\n",
    "\n",
    "    encoder = GRU(units, dropout=drop,return_state=True)\n",
    "    _,encoder_states = encoder(encoder_inputs)\n",
    "    if bn:\n",
    "        encoder_states=layers.BatchNormalization()(encoder_states)\n",
    "    decoder=layers.RepeatVector(48)(encoder_states)\n",
    "    decoder_gru = GRU(units, dropout=drop, return_sequences=True, return_state=False)\n",
    "    decoder = decoder_gru(decoder, initial_state=encoder_states)\n",
    "    \n",
    "    out = layers.TimeDistributed(Dense(channel))(decoder)\n",
    "    model = models.Model(encoder_inputs, out)\n",
    "    #model.compile(loss='mse', optimizer=RMSprop(),metrics=['accuracy'])\n",
    "    model.compile(loss='mse', optimizer=RMSprop(),metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatedDNN(features):\n",
    "#     model = Sequential()\n",
    "#     model.add(layers.Input(shape=(72,features)))\n",
    "#     model.add(layers.Dense(2, activation='relu'))\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "    model = Sequential([\n",
    "    Lambda(lambda x: x[:, -1:, :]),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(48*6),\n",
    "    Reshape([48, 6])\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=RMSprop(),metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(features):\n",
    "    model = Sequential()\n",
    "    lstm = LSTM(50, return_sequences=True, activation='relu', input_shape=(72, features))\n",
    "    model.add(LSTM(50, return_sequences=True, activation='relu', input_shape=(72, features)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units = 1))\n",
    "    model.add(Dense(1, activation= \"sigmoid\"))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadToModel(files, formating, pathFiles, postfx, params, predicts):\n",
    "    T = 72\n",
    "    D = 1\n",
    "    X = []\n",
    "    Y = []\n",
    "    for fileName in files:\n",
    "        accuracy = 0\n",
    "        #df = pd.read_csv(pathFiles + fileName + postfx + formating, sep=',')\n",
    "        df = pd.read_csv(pathFiles + fileName + formating, sep=',')\n",
    "        #df['pm10'] = df['pm10'].map(lambda a: pm10_index(a))\n",
    "        #df['pm10'] = df['pm10'].astype(int)\n",
    "        df['date_time'] = df['date_time'].astype(\"|S\")\n",
    "        df['season'] = df['season'].astype(\"|S\")\n",
    "        #df['forecast_windDirection'] = df['forecast_windDirection'].astype(\"|S\")\n",
    "        #df['real_winddir'] = df['real_winddir'].astype(\"|S\")\n",
    "        df['date_time'] = df['date_time'].map(lambda a: get_time(a))\n",
    "        df['date_time'] = df['date_time'].astype(np.float64)\n",
    "        df['season'] = df['season'].map(lambda a: get_season(a))\n",
    "        df['season'] = df['season'].astype(np.float64)\n",
    "        #df['forecast_windDirection'] = df['forecast_windDirection'].map(lambda a: get_winddir(a))\n",
    "        df['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        #df['real_winddir'] = df['real_winddir'].map(lambda a: get_winddir(a))\n",
    "        #df['real_winddir'] = df['real_winddir'].astype(np.float64)\n",
    "        #df['pm10'] = df['pm10'].astype('int')\n",
    "        df['station_id'] = df['station_id'].astype(int)\n",
    "        df['forecast_tempC'] = df['forecast_tempC'].astype(np.float64)\n",
    "        df['forecast_humidity'] = df['forecast_humidity'].astype(np.float64)\n",
    "        df['forecast_windSpeed'] = df['forecast_windSpeed'].astype(np.float64)\n",
    "#         X,y = create_xy(df[['station_id','season','real_temp','real_humidity','real_windspd','real_winddir','forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection']],df[['pm10']],72, 48)\n",
    "        X,y = create_xy(df[['station_id','season','forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection']],df[['pm10']],72, 48)\n",
    "        accuracy = 0.0\n",
    "        print(fileName + ' begins prediction')\n",
    "#        model = GradientBoostingRegressor(learning_rate=0.05,max_features=0.6,max_leaf_nodes=31,n_estimators=200)\n",
    "        model = seq2seq(5,True,0.5,6,1)\n",
    "#        model = gatedDNN(6)\n",
    "#        model.compile(optimizer=RMSprop(), loss='mse')\n",
    "        \n",
    "        #model = MultiOutputRegressor(gbm,-1)\n",
    "        #model = lgb.LGBMRegressor()\n",
    "        #model = XGBClassifier()\n",
    "        #model = XGBClassifier(gamma=0.1, max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8)\n",
    "        kf = KFold(n_splits=5)\n",
    "\n",
    "#         nsamples, nx, ny = np.array(X).shape\n",
    "#         X = X.reshape((nsamples,nx*ny))\n",
    "#         nsamples2, nx2 = np.array(y).shape\n",
    "#         y = y.reshape((nsamples2,nx2))\n",
    "        print(X.shape)\n",
    "        print(y.shape)\n",
    "#         epochs = 2\n",
    "#         batch_size = 32\n",
    "        for trainI,testI in kf.split(X):\n",
    "            model.fit(X[trainI],y[trainI])\n",
    "            predictions = model.predict(X[testI])\n",
    "            predicts.append(predictions)\n",
    "#             print(\"*************\")\n",
    "#             print(y[testI])\n",
    "#            accuracy += accuracy_score(y[testI], predictions)\n",
    "        \n",
    "#         _, test_acc = model.evaluate(X,y,verbose=0)\n",
    "#         accuracy = test_acc\n",
    "#         print('Accuracy ' + fileName + ': %.3f' % (accuracy/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgiaParaskevi begins prediction\n",
      "(43729, 72, 6)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      " 6976/34983 [====>.........................] - ETA: 1:30 - loss: 10887069.6920 - acc: 0.0012"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-4593ff38d691>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloadToModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles_postfix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-79-87be91aa1bbd>\u001b[0m in \u001b[0;36mloadToModel\u001b[1;34m(files, formating, pathFiles, postfx, params, predicts)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m#         batch_size = 32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrainI\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestI\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrainI\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrainI\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtestI\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mpredicts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loadToModel(file_names, files_format, files_path, files_postfix, parameters,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CleanFiles/AgiaParaskevi.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>station_id</th>\n",
       "      <th>forecast_tempC</th>\n",
       "      <th>forecast_humidity</th>\n",
       "      <th>season</th>\n",
       "      <th>forecast_windDirection</th>\n",
       "      <th>forecast_windSpeed</th>\n",
       "      <th>pm10</th>\n",
       "      <th>pm25</th>\n",
       "      <th>o3</th>\n",
       "      <th>no</th>\n",
       "      <th>no2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>Winter</td>\n",
       "      <td>119.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>Winter</td>\n",
       "      <td>238.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>69</td>\n",
       "      <td>Winter</td>\n",
       "      <td>357.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>Winter</td>\n",
       "      <td>355.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43843</th>\n",
       "      <td>2020-12-31 19:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>73</td>\n",
       "      <td>Winter</td>\n",
       "      <td>215.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43844</th>\n",
       "      <td>2020-12-31 20:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>74</td>\n",
       "      <td>Winter</td>\n",
       "      <td>222.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43845</th>\n",
       "      <td>2020-12-31 21:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>Winter</td>\n",
       "      <td>228.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43846</th>\n",
       "      <td>2020-12-31 22:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>Winter</td>\n",
       "      <td>240.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43847</th>\n",
       "      <td>2020-12-31 23:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>Winter</td>\n",
       "      <td>251.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43848 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date_time  station_id  forecast_tempC  forecast_humidity  \\\n",
       "0      2016-01-01 00:00:00           2               3                 69   \n",
       "1      2016-01-01 01:00:00           2               3                 69   \n",
       "2      2016-01-01 02:00:00           2               3                 69   \n",
       "3      2016-01-01 03:00:00           2               3                 69   \n",
       "4      2016-01-01 04:00:00           2               3                 70   \n",
       "...                    ...         ...             ...                ...   \n",
       "43843  2020-12-31 19:00:00           2              13                 73   \n",
       "43844  2020-12-31 20:00:00           2              13                 74   \n",
       "43845  2020-12-31 21:00:00           2              12                 74   \n",
       "43846  2020-12-31 22:00:00           2              12                 74   \n",
       "43847  2020-12-31 23:00:00           2              11                 73   \n",
       "\n",
       "       season  forecast_windDirection  forecast_windSpeed    pm10  pm25  \\\n",
       "0      Winter                     0.0                23.0    27.0  22.0   \n",
       "1      Winter                   119.0                22.0    30.0  29.0   \n",
       "2      Winter                   238.0                20.0    30.0  25.0   \n",
       "3      Winter                   357.0                19.0     8.0   8.0   \n",
       "4      Winter                   355.0                17.0     9.0  10.0   \n",
       "...       ...                     ...                 ...     ...   ...   \n",
       "43843  Winter                   215.0                21.0 -9999.0  12.0   \n",
       "43844  Winter                   222.0                17.0 -9999.0  16.0   \n",
       "43845  Winter                   228.0                14.0 -9999.0  21.0   \n",
       "43846  Winter                   240.0                12.0 -9999.0  14.0   \n",
       "43847  Winter                   251.0                10.0 -9999.0  15.0   \n",
       "\n",
       "           o3   no   no2  \n",
       "0     -9999.0  1.0  12.0  \n",
       "1     -9999.0  1.0  16.0  \n",
       "2     -9999.0  1.0   7.0  \n",
       "3     -9999.0  1.0   8.0  \n",
       "4     -9999.0  1.0  10.0  \n",
       "...       ...  ...   ...  \n",
       "43843    47.0  1.0   5.0  \n",
       "43844    40.0  1.0   5.0  \n",
       "43845    48.0  1.0   5.0  \n",
       "43846    50.0  1.0   5.0  \n",
       "43847    45.0  1.0   6.0  \n",
       "\n",
       "[43848 rows x 12 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
