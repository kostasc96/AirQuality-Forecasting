{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, GRU, SimpleRNN, Dense, GlobalMaxPool1D,Reshape\n",
    "# from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import layers,models\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = 'CleanFiles/'\n",
    "files_format = '.csv'\n",
    "files_postfix = 'Extract'\n",
    "file_names = ['AgiaParaskevi','Aristotelous','Athens','Elefsina','Koropi','Liosia',\n",
    "              'Lykovrisi','Marousi','NeaSmirni','Patision','Peristeri',\n",
    "              'Pireus','Thrakomakedones']\n",
    "#file_names = ['AgiaParaskevi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pm10_index(val):\n",
    "    if val <= 25.0:\n",
    "        return 0\n",
    "    elif 26.0 <= val <= 50.0:\n",
    "        return 1\n",
    "    elif 51.0 <= val <= 90.0:\n",
    "        return 2\n",
    "    elif 91.0 <= val <= 180.0:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(tmp):\n",
    "    return tmp[11:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(tmp):\n",
    "    if tmp == 'Spring':\n",
    "        return '1'\n",
    "    elif tmp == 'Spring/Summer':\n",
    "        return '2'\n",
    "    elif tmp == 'Summer':\n",
    "        return '3'\n",
    "    elif tmp == 'Summer/Autumn':\n",
    "        return '4'\n",
    "    elif tmp == 'Autumn':\n",
    "        return '5'\n",
    "    elif tmp == 'Autumn/Winter':\n",
    "        return '6'\n",
    "    elif tmp == 'Winter/Spring':\n",
    "        return '7'\n",
    "    else:\n",
    "        return '8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winddir(tmp):\n",
    "    if tmp == 'N':\n",
    "        return '1'\n",
    "    elif tmp == 'NNE':\n",
    "        return '2'\n",
    "    elif tmp == 'NE':\n",
    "        return '3'\n",
    "    elif tmp == 'ENE':\n",
    "        return '4'\n",
    "    elif tmp == 'E':\n",
    "        return '5'\n",
    "    elif tmp == 'ESE':\n",
    "        return '6'\n",
    "    elif tmp == 'SE':\n",
    "        return '7'\n",
    "    elif tmp == 'SSE':\n",
    "        return '8'\n",
    "    elif tmp == 'S':\n",
    "        return '9'\n",
    "    elif tmp == 'SSW':\n",
    "        return '10'\n",
    "    elif tmp == 'SW':\n",
    "        return '11'\n",
    "    elif tmp == 'WSW':\n",
    "        return '12'\n",
    "    elif tmp == 'W':\n",
    "        return '13'\n",
    "    elif tmp == 'WNW':\n",
    "        return '14'\n",
    "    elif tmp == 'NW':\n",
    "        return '15'\n",
    "    else:\n",
    "        return '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neasmirni = pd.read_csv('CleanFiles/NeaSmirniExtract.csv', sep=',')\n",
    "#neasmirni = neasmirni[['date_time','station_id','season','real_temp','real_windspd','real_winddir','real_humidity','forecast_tempC','forecast_windSpeed','forecast_windDirection','forecast_humidity','pm10']]\n",
    "#neasmirni['pm10'] = neasmirni['pm10'].map(lambda a: pm10_index(a))\n",
    "#temp = pd.read_csv('CleanFiles/PeristeriExtract.csv', sep=',')\n",
    "#agiaparaskevi = pd.read_csv('CleanFiles/AgiaParaskeviExtract.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = 72\n",
    "# D = 1\n",
    "# X = []\n",
    "# Y = []\n",
    "# for t in range(len(neasmirni) - T):\n",
    "#     x = neasmirni[t:t+T]\n",
    "#     X.append(x)\n",
    "#     y = neasmirni[t:t+T]\n",
    "#     Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xy(series, series2, window_size, prediction_horizon, shuffle = False):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(0, len(series)):\n",
    "        if len(series[(i + window_size):(i + window_size + prediction_horizon)]) < prediction_horizon:\n",
    "            break\n",
    "        x.append(np.array(series[i:(i + window_size)]))\n",
    "        y.append(np.array(series2[(i + window_size):(i + window_size + prediction_horizon)]))\n",
    "#         x.append(np.array(series[i:i+window_size][['station_id','season','real_temp','real_humidity','real_windspd','real_winddir','forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection']]))\n",
    "#         y.append(np.array(series[i+window_size:i+window_size+prediction_horizon]['pm10']))\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': 2000,\n",
    "    'max_depth': 4,\n",
    "    'num_leaves': 2**4,\n",
    "    'learning_rate': 0.1,\n",
    "    'boosting_type': 'dart'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units,drop,out_features):\n",
    "\n",
    "    input=layers.Input(shape=(72,10))\n",
    "    result=GRU(units,dropout=drop,return_sequences=False)(input)\n",
    "    result=layers.Dense(2)(result)\n",
    "    result=Reshape(target_shape=(48,out_features))(result)\n",
    "    \n",
    "    return Model(inputs=input,outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq(units,bn,drop=0.0,channel=1):\n",
    "    encoder_inputs = layers.Input(shape=(72,10))\n",
    "\n",
    "    encoder = GRU(units, dropout=drop,return_state=True)\n",
    "    _,encoder_states = encoder(encoder_inputs)\n",
    "    if bn:\n",
    "        encoder_states=layers.BatchNormalization()(encoder_states)\n",
    "    decoder=layers.RepeatVector(48)(encoder_states)\n",
    "    decoder_gru = GRU(units, dropout=drop, return_sequences=True, return_state=False)\n",
    "    decoder = decoder_gru(decoder, initial_state=encoder_states)\n",
    "    \n",
    "    out = layers.TimeDistributed(Dense(channel))(decoder)\n",
    "    return models.Model(encoder_inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gatedDNN():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape=(76,)))\n",
    "    model.add(layers.Dense(2, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadToModel(files, formating, pathFiles, postfx, params, predicts):\n",
    "    T = 72\n",
    "    D = 1\n",
    "    X = []\n",
    "    Y = []\n",
    "    for fileName in files:\n",
    "        accuracy = 0\n",
    "        df = pd.read_csv(pathFiles + fileName + postfx + formating, sep=',')\n",
    "        #df['pm10'] = df['pm10'].astype(int)\n",
    "        df['pm10'] = df['pm10'].map(lambda a: pm10_index(a))\n",
    "        df['pm10'] = df['pm10'].astype(int)\n",
    "        df['date_time'] = df['date_time'].astype(\"|S\")\n",
    "        df['season'] = df['season'].astype(\"|S\")\n",
    "        df['forecast_windDirection'] = df['forecast_windDirection'].astype(\"|S\")\n",
    "        df['real_winddir'] = df['real_winddir'].astype(\"|S\")\n",
    "        df['date_time'] = df['date_time'].map(lambda a: get_time(a))\n",
    "        df['date_time'] = df['date_time'].astype(np.float64)\n",
    "        df['season'] = df['season'].map(lambda a: get_season(a))\n",
    "        df['season'] = df['season'].astype(np.float64)\n",
    "        df['forecast_windDirection'] = df['forecast_windDirection'].map(lambda a: get_winddir(a))\n",
    "        df['forecast_windDirection'] = df['forecast_windDirection'].astype(np.float64)\n",
    "        df['real_winddir'] = df['real_winddir'].map(lambda a: get_winddir(a))\n",
    "        df['real_winddir'] = df['real_winddir'].astype(np.float64)\n",
    "        #df['pm10'] = df['pm10'].astype('int')\n",
    "        df['station_id'] = df['station_id'].astype(np.float64)\n",
    "        df['forecast_tempC'] = df['forecast_tempC'].astype(np.float64)\n",
    "        df['forecast_humidity'] = df['forecast_humidity'].astype(np.float64)\n",
    "        X,y = create_xy(df[['station_id','season','real_temp','real_humidity','real_windspd','real_winddir','forecast_tempC','forecast_humidity','forecast_windSpeed','forecast_windDirection']],df[['pm10']],72, 48)\n",
    "        accuracy = 0.0\n",
    "        print(fileName + ' begins prediction')\n",
    "#        model = GradientBoostingRegressor(learning_rate=0.05,max_features=0.6,max_leaf_nodes=31,n_estimators=200)\n",
    "        model = seq2seq(10,False,0.5,1)\n",
    "        model.compile(loss='mse', optimizer=RMSprop(),metrics=['accuracy'])\n",
    "#        model.compile(optimizer=RMSprop(), loss='mse')\n",
    "        \n",
    "        #model = MultiOutputRegressor(gbm,-1)\n",
    "        #model = lgb.LGBMRegressor()\n",
    "        #model = XGBClassifier()\n",
    "        #model = XGBClassifier(gamma=0.1, max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8)\n",
    "        kf = KFold(n_splits=5)\n",
    "\n",
    "#         nsamples, nx, ny = np.array(X).shape\n",
    "#         X = X.reshape((nsamples,nx*ny))\n",
    "#         nsamples2, nx2 = np.array(y).shape\n",
    "#         y = y.reshape((nsamples2,nx2))\n",
    "        print(X.shape)\n",
    "        print(y.shape)\n",
    "        #encoder1 = LabelEncoder() \n",
    "        for trainI,testI in kf.split(X):\n",
    "            model.fit(X[trainI],y[trainI])\n",
    "            predictions = model.predict(X[testI])\n",
    "#             print(predictions)\n",
    "#             print(\"*************\")\n",
    "#             print(y[testI])\n",
    "#            accuracy += accuracy_score(y[testI], predictions)\n",
    "        \n",
    "#         _, test_acc = model.evaluate(X,y,verbose=0)\n",
    "#         accuracy = test_acc\n",
    "#         print('Accuracy ' + fileName + ': %.3f' % (accuracy/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgiaParaskevi begins prediction\n",
      "WARNING:tensorflow:From c:\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "WARNING:tensorflow:From c:\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 117s 3ms/sample - loss: 0.2412 - acc: 0.8288\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 118s 3ms/sample - loss: 0.2285 - acc: 0.8283\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 116s 3ms/sample - loss: 0.1974 - acc: 0.8347\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 118s 3ms/sample - loss: 0.2314 - acc: 0.8221\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 116s 3ms/sample - loss: 0.2282 - acc: 0.8289\n",
      "Aristotelous begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 121s 3ms/sample - loss: 0.5832 - acc: 0.5022\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 118s 3ms/sample - loss: 0.5627 - acc: 0.5193\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 120s 3ms/sample - loss: 0.5755 - acc: 0.5018\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 118s 3ms/sample - loss: 0.5627 - acc: 0.5162\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 118s 3ms/sample - loss: 0.5824 - acc: 0.5108\n",
      "Athens begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 118s 3ms/sample - loss: 0.6109 - acc: 0.5018\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 118s 3ms/sample - loss: 0.5612 - acc: 0.5192\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 118s 3ms/sample - loss: 0.5739 - acc: 0.5017\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 118s 3ms/sample - loss: 0.5600 - acc: 0.5162\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 118s 3ms/sample - loss: 0.5792 - acc: 0.5108\n",
      "Elefsina begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 114s 3ms/sample - loss: 0.3900 - acc: 0.5780\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 114s 3ms/sample - loss: 0.4137 - acc: 0.5326\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 114s 3ms/sample - loss: 0.3813 - acc: 0.5833\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 114s 3ms/sample - loss: 0.4150 - acc: 0.5371\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 114s 3ms/sample - loss: 0.4212 - acc: 0.4257\n",
      "Koropi begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 122s 3ms/sample - loss: 0.4546 - acc: 0.4487\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 122s 3ms/sample - loss: 0.4502 - acc: 0.4199\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 115s 3ms/sample - loss: 0.4169 - acc: 0.4272\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 115s 3ms/sample - loss: 0.4492 - acc: 0.4143\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 116s 3ms/sample - loss: 0.4503 - acc: 0.4356\n",
      "Liosia begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 123s 4ms/sample - loss: 0.5210 - acc: 0.5428\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 120s 3ms/sample - loss: 0.5154 - acc: 0.5431\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 121s 3ms/sample - loss: 0.4989 - acc: 0.6561\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 132s 4ms/sample - loss: 0.5827 - acc: 0.3652\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 125s 4ms/sample - loss: 0.5280 - acc: 0.4615\n",
      "Lykovrisi begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 129s 4ms/sample - loss: 0.4612 - acc: 0.5877\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 123s 4ms/sample - loss: 0.4506 - acc: 0.6084\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 120s 3ms/sample - loss: 0.4498 - acc: 0.6130\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 126s 4ms/sample - loss: 0.4465 - acc: 0.6342\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 122s 3ms/sample - loss: 0.4718 - acc: 0.5454\n",
      "Marousi begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 121s 3ms/sample - loss: 0.4961 - acc: 0.5507\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 118s 3ms/sample - loss: 0.5146 - acc: 0.4766\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 120s 3ms/sample - loss: 0.5014 - acc: 0.5336\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 116s 3ms/sample - loss: 0.5170 - acc: 0.4776\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 115s 3ms/sample - loss: 0.5173 - acc: 0.4333\n",
      "NeaSmirni begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 117s 3ms/sample - loss: 0.4810 - acc: 0.4619\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 115s 3ms/sample - loss: 0.5192 - acc: 0.3852\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 116s 3ms/sample - loss: 0.4934 - acc: 0.4017\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 115s 3ms/sample - loss: 0.5209 - acc: 0.3704\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 115s 3ms/sample - loss: 0.5313 - acc: 0.3664\n",
      "Patision begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 120s 3ms/sample - loss: 0.6174 - acc: 0.5023\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 120s 3ms/sample - loss: 0.5623 - acc: 0.5193\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 120s 3ms/sample - loss: 0.5757 - acc: 0.5017\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 121s 3ms/sample - loss: 0.5603 - acc: 0.5162\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 128s 4ms/sample - loss: 0.5798 - acc: 0.5107\n",
      "Peristeri begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 122s 3ms/sample - loss: 0.6003 - acc: 0.4085\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 121s 3ms/sample - loss: 0.6031 - acc: 0.3688\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 120s 3ms/sample - loss: 0.5881 - acc: 0.3742\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 120s 3ms/sample - loss: 0.6256 - acc: 0.3638\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 120s 3ms/sample - loss: 0.6153 - acc: 0.3922\n",
      "Pireus begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 121s 3ms/sample - loss: 0.6486 - acc: 0.4971\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 121s 3ms/sample - loss: 0.6054 - acc: 0.4984\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 122s 3ms/sample - loss: 0.6164 - acc: 0.4915\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 124s 4ms/sample - loss: 0.6213 - acc: 0.4972\n",
      "Train on 34984 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34984/34984 [==============================] - 121s 3ms/sample - loss: 0.6161 - acc: 0.5114\n",
      "Thrakomakedones begins prediction\n",
      "(43729, 72, 10)\n",
      "(43729, 48, 1)\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 120s 3ms/sample - loss: 0.2278 - acc: 0.8316\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 119s 3ms/sample - loss: 0.2453 - acc: 0.8264\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 118s 3ms/sample - loss: 0.2083 - acc: 0.8383\n",
      "Train on 34983 samples\n",
      "34983/34983 [==============================] - 119s 3ms/sample - loss: 0.2397 - acc: 0.8282\n",
      "Train on 34984 samples\n",
      "34984/34984 [==============================] - 119s 3ms/sample - loss: 0.2489 - acc: 0.8169\n"
     ]
    }
   ],
   "source": [
    "loadToModel(file_names, files_format, files_path, files_postfix, parameters,predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
